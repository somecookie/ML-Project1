{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'train.csv' # TODO: download train data and supply path here \n",
    "y, x, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n",
      "data built\n",
      "(250000,)\n",
      "(31,)\n"
     ]
    }
   ],
   "source": [
    "from functions import *\n",
    "print(y.shape)\n",
    "y, tx = build_model_data(y, x)\n",
    "print(y.shape)\n",
    "print((tx.T@y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step 0: 1.0\n",
      "loss at step 1: 1.0\n",
      "loss at step 2: 0.9292541183393771\n",
      "loss at step 3: 0.8585082366787544\n",
      "loss at step 4: 0.7877623550181316\n",
      "loss at step 5: 0.7477159715484784\n",
      "loss at step 6: 0.8027874662446284\n",
      "loss at step 7: 0.734891975771335\n",
      "loss at step 8: 0.7374964879012589\n",
      "loss at step 9: 0.8003053241314226\n",
      "loss at step 10: 0.7297003883089711\n",
      "loss at step 11: 0.7701096940409321\n",
      "loss at step 12: 0.7778874399217361\n",
      "loss at step 13: 0.7259827027538156\n",
      "loss at step 14: 0.7938400012239093\n",
      "loss at step 15: 0.7231645046390235\n",
      "loss at step 16: 0.8154024299756669\n",
      "loss at step 17: 0.8269956176770503\n",
      "loss at step 18: 0.7562497360164279\n",
      "loss at step 19: 0.7505122145330585\n",
      "loss at step 20: 0.8464999832217154\n",
      "loss at step 21: 0.7757541015610927\n",
      "loss at step 22: 0.7264849987521256\n",
      "loss at step 23: 0.7291428824648859\n",
      "loss at step 24: 0.796134664115496\n",
      "loss at step 25: 0.7257363601221044\n",
      "loss at step 26: 0.7796100213715076\n",
      "loss at step 27: 0.8392601644233153\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 1e-7\n",
    "delta = 10\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.zeros(len(tx.T))\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gradient_losses, gradient_ws = gradient_descent2(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Gradient Descent: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7229263473566381\n"
     ]
    }
   ],
   "source": [
    "totLoss = compute_loss2(y, tx, gradient_ws)\n",
    "print(totLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'test.csv' # TODO: download train data and supply path here \n",
    "_, x_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data built\n"
     ]
    }
   ],
   "source": [
    "_, tx_test = build_model_data(_, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_labels(gradient_ws, tx_test)\n",
    "name = 'prediction5.csv'\n",
    "create_csv_submission(ids_test, prediction, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'train.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'output.csv'\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
