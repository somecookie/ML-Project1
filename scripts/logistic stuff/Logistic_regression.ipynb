{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74768a95-fc2d-4004-a017-80c9d11b72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfcb9b38-048a-4817-b7ba-72800a33010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51250b6b-265c-41f4-a1e2-974ca8520a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_propre import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454e6948-96eb-4312-9af3-a0ea6c396b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'train.csv' # TODO: download train data and supply path here \n",
    "y, x, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a342e1-cc2f-4465-9534-f9023fb9c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, separate the data sets in 3 categories\n",
    "x1, x2, x3, y1, y2, y3 = split_cat(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8e1e2c0d-9622-4957-a058-37bd2450683e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49956, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y1Train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e893a70a-2854-45f7-827e-489bd93b025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_propre import *\n",
    "#logistic regression: median replacement + normalize\n",
    "ratio = 0.5\n",
    "x1Train, y1Train, x1Test, y1Test = split_data(x1, y1, ratio)\n",
    "#simple normalization\n",
    "x1TrainClean = x1Train\n",
    "x1TestClean = x1Test\n",
    "#put -999.0 values to nan\n",
    "x1TrainClean[x1TrainClean == -999] = np.nan\n",
    "x1TestClean[x1TestClean == -999] = np.nan\n",
    "#this computes the median without the influence of the -999s\n",
    "_, _, x1TrainMedian = clean_data(x1TrainClean)\n",
    "_, _, x1TestMedian = clean_data(x1TestClean)\n",
    "#replace Nan with the mean of the corresponding column\n",
    "for i in range(len(x1TrainMedian)):\n",
    "    x1TrainClean[:,i] = np.nan_to_num(x1TrainClean[:,i], nan=x1TrainMedian[i])\n",
    "for i in range(len(x1TestMedian)):\n",
    "    x1TestClean[:,i] = np.nan_to_num(x1TestClean[:,i], nan=x1TestMedian[i])\n",
    "#then, normalize this\n",
    "x1TrainClean, _, _ = clean_data(x1TrainClean)\n",
    "x1TestClean, _, _ = clean_data(x1TestClean)\n",
    "#create ridge compatible features (hopefully)\n",
    "x1Train = build_features_logistic(x1TrainClean, y1Train)\n",
    "#logistic regression\n",
    "gamma = 0.00001\n",
    "lambda_ = 0.00001\n",
    "max_iters = 10000\n",
    "initial_w = 0.0*np.ones((len(x1Train.T),1))\n",
    "wLog1, loss = reg_logistic_regression(y1Train, x1Train, initial_w, max_iters, gamma, lambda_)\n",
    "#test accuracy and stuff\n",
    "x1Test = build_features_logistic(x1TestClean, y1Test)\n",
    "accLog1 = get_accuracyLog(sigmoid(x1Test@wLog1), y1Test)\n",
    "print(\"Accuracy for category 1 with logistic regression with median is\" , accLog1*100, \"%.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d41bd351-1312-4e70-a1f6-153862baffd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating diagonal... Be patient ( 1 / 10 ).\n",
      "Calculating S... Be patient ( 1 / 10 ).\n",
      "Calculating H... Be patient ( 1 / 10 ).\n",
      "Inverting... Be patient ( 1 / 10 ).\n",
      "Loss at time  0  is  [15589.97971807]\n",
      "Calculating diagonal... Be patient ( 2 / 10 ).\n",
      "Calculating S... Be patient ( 2 / 10 ).\n",
      "Calculating H... Be patient ( 2 / 10 ).\n",
      "Inverting... Be patient ( 2 / 10 ).\n",
      "Loss at time  1  is  [13615.90653519]\n",
      "Calculating diagonal... Be patient ( 3 / 10 ).\n",
      "Calculating S... Be patient ( 3 / 10 ).\n",
      "Calculating H... Be patient ( 3 / 10 ).\n",
      "Inverting... Be patient ( 3 / 10 ).\n",
      "Loss at time  2  is  [12641.72338971]\n",
      "Calculating diagonal... Be patient ( 4 / 10 ).\n",
      "Calculating S... Be patient ( 4 / 10 ).\n",
      "Calculating H... Be patient ( 4 / 10 ).\n",
      "Inverting... Be patient ( 4 / 10 ).\n",
      "Loss at time  3  is  [12156.47596632]\n",
      "Calculating diagonal... Be patient ( 5 / 10 ).\n",
      "Calculating S... Be patient ( 5 / 10 ).\n",
      "Calculating H... Be patient ( 5 / 10 ).\n",
      "Inverting... Be patient ( 5 / 10 ).\n",
      "Loss at time  4  is  [11933.23000398]\n",
      "Calculating diagonal... Be patient ( 6 / 10 ).\n",
      "Calculating S... Be patient ( 6 / 10 ).\n",
      "Calculating H... Be patient ( 6 / 10 ).\n",
      "Inverting... Be patient ( 6 / 10 ).\n",
      "Loss at time  5  is  [11842.60159494]\n",
      "Calculating diagonal... Be patient ( 7 / 10 ).\n",
      "Calculating S... Be patient ( 7 / 10 ).\n",
      "Calculating H... Be patient ( 7 / 10 ).\n",
      "Inverting... Be patient ( 7 / 10 ).\n",
      "Loss at time  6  is  [11810.56469327]\n",
      "Calculating diagonal... Be patient ( 8 / 10 ).\n",
      "Calculating S... Be patient ( 8 / 10 ).\n",
      "Calculating H... Be patient ( 8 / 10 ).\n",
      "Inverting... Be patient ( 8 / 10 ).\n",
      "Loss at time  7  is  [11800.55434755]\n",
      "Calculating diagonal... Be patient ( 9 / 10 ).\n",
      "Calculating S... Be patient ( 9 / 10 ).\n",
      "Calculating H... Be patient ( 9 / 10 ).\n",
      "Inverting... Be patient ( 9 / 10 ).\n",
      "Loss at time  8  is  [11797.70091198]\n",
      "Calculating diagonal... Be patient ( 10 / 10 ).\n",
      "Calculating S... Be patient ( 10 / 10 ).\n",
      "Calculating H... Be patient ( 10 / 10 ).\n",
      "Inverting... Be patient ( 10 / 10 ).\n",
      "Loss at time  9  is  [11796.934148]\n",
      "Accuracy for category 1 with logistic regression with median is 75.0328853302831 %.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from functions_propre import *\n",
    "#logistic regression WITH NEWTON: median replacement + normalize\n",
    "ratio = 0.3\n",
    "x1Train, y1Train, x1Test, y1Test = split_data(x1, y1, ratio)\n",
    "#simple normalization\n",
    "x1TrainClean = x1Train\n",
    "x1TestClean = x1Test\n",
    "#put -999.0 values to nan\n",
    "x1TrainClean[x1TrainClean == -999] = np.nan\n",
    "x1TestClean[x1TestClean == -999] = np.nan\n",
    "#this computes the median without the influence of the -999s\n",
    "_, _, x1TrainMedian = clean_data(x1TrainClean)\n",
    "_, _, x1TestMedian = clean_data(x1TestClean)\n",
    "#replace Nan with the mean of the corresponding column\n",
    "for i in range(len(x1TrainMedian)):\n",
    "    x1TrainClean[:,i] = np.nan_to_num(x1TrainClean[:,i], nan=x1TrainMedian[i])\n",
    "for i in range(len(x1TestMedian)):\n",
    "    x1TestClean[:,i] = np.nan_to_num(x1TestClean[:,i], nan=x1TestMedian[i])\n",
    "#then, normalize this\n",
    "x1TrainClean, _, _ = clean_data(x1TrainClean)\n",
    "x1TestClean, _, _ = clean_data(x1TestClean)\n",
    "#create ridge compatible features (hopefully)\n",
    "x1Train = build_features_logistic(x1TrainClean, y1Train)\n",
    "#logistic regression\n",
    "gamma = 0.5\n",
    "lambda_ = 0\n",
    "max_iters = 10\n",
    "initial_w = 0.0*np.ones((len(x1Train.T),1))\n",
    "wLog1, loss = logistic_reg_newton(y1Train, x1Train, initial_w, max_iters, gamma, lambda_)\n",
    "#test accuracy and stuff\n",
    "x1Test = build_features_logistic(x1TestClean, y1Test)\n",
    "accLog1 = get_accuracyLog(sigmoid(x1Test@wLog1), y1Test)\n",
    "print(\"Accuracy for category 1 with logistic regression with median is\" , accLog1*100, \"%.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9678b54d-7f0c-45e5-8797-347505c9911b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from functions_propre import *\n",
    "#logistic regression WITH NEWTON: median replacement + normalize - CATEGORY 2\n",
    "ratio = 0.2\n",
    "x2Train, y2Train, x2Test, y2Test = split_data(x2, y2, ratio)\n",
    "#simple normalization\n",
    "x2TrainClean = x2Train\n",
    "x2TestClean = x2Test\n",
    "#put -999.0 values to nan\n",
    "x2TrainClean[x2TrainClean == -999] = np.nan\n",
    "x2TestClean[x2TestClean == -999] = np.nan\n",
    "#this computes the median without the influence of the -999s\n",
    "_, _, x2TrainMedian = clean_data(x2TrainClean)\n",
    "_, _, x2TestMedian = clean_data(x2TestClean)\n",
    "#replace Nan with the mean of the corresponding column\n",
    "for i in range(len(x2TrainMedian)):\n",
    "    x2TrainClean[:,i] = np.nan_to_num(x2TrainClean[:,i], nan=x2TrainMedian[i])\n",
    "for i in range(len(x2TestMedian)):\n",
    "    x2TestClean[:,i] = np.nan_to_num(x2TestClean[:,i], nan=x2TestMedian[i])\n",
    "#then, normalize this\n",
    "x2TrainClean, _, _ = clean_data(x2TrainClean)\n",
    "x2TestClean, _, _ = clean_data(x2TestClean)\n",
    "#create ridge compatible features (hopefully)\n",
    "x2Train = build_features_logistic(x2TrainClean, y2Train)\n",
    "#logistic regression\n",
    "gamma = 0.1\n",
    "lambda_ = 0\n",
    "max_iters = 10\n",
    "initial_w = 0.0*np.ones((len(x2Train.T),1))\n",
    "wLog2, loss = logistic_reg_newton(y2Train, x2Train, initial_w, max_iters, gamma, lambda_)\n",
    "#test accuracy and stuff\n",
    "x2Test = build_features_logistic(x2TestClean, y2Test)\n",
    "accLog2 = get_accuracyLog(sigmoid(x2Test@wLog2), y2Test)\n",
    "print(\"Accuracy for category 2 with logistic regression with median is\" , accLog2*100, \"%.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a4fb18-2cf7-4d73-8cb2-3e34dacfbd27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
