{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d50b836a-e39b-430d-9900-2a1bdaf77560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db2c963-ea8b-4481-a007-3c725a27a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'train.csv' # TODO: download train data and supply path here \n",
    "y, x, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a03f44-59d2-4926-a0c9-ce2cae4acd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_propre import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71eaa7be-7858-4c16-a663-6b586dc462a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, separate the data sets in 3 categories\n",
    "x1, x2, x3, y1, y2, y3 = split_cat(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c262c0-80ef-4df5-b9ca-ff7a75bc671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for category 1 with ridge with median is 85.0 %.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#try SOMETHING WITH THE MEAN + NORMALIZE\n",
    "#CAT1\n",
    "#separate data\n",
    "ratio = 0.99\n",
    "x1Train, y1Train, x1Test, y1Test = split_data(x1, y1, ratio)\n",
    "#simple normalization\n",
    "x1TrainClean = x1Train\n",
    "x1TestClean = x1Test\n",
    "#put -999.0 values to nan\n",
    "x1TrainClean[x1TrainClean == -999] = np.nan\n",
    "x1TestClean[x1TestClean == -999] = np.nan\n",
    "#this computes the median without the influence of the -999s\n",
    "_, x1TrainMean, _ = clean_data(x1TrainClean)\n",
    "_, x1TestMean, _ = clean_data(x1TestClean)\n",
    "#replace Nan with the mean of the corresponding column\n",
    "for i in range(len(x1TrainMean)):\n",
    "    x1TrainClean[:,i] = np.nan_to_num(x1TrainClean[:,i], nan=x1TrainMean[i])\n",
    "for i in range(len(x1TestMean)):\n",
    "    x1TestClean[:,i] = np.nan_to_num(x1TestClean[:,i], nan=x1TestMean[i])\n",
    "#then, normalize this\n",
    "x1TrainClean, _, _ = clean_data(x1TrainClean)\n",
    "x1TestClean, _, _ = clean_data(x1TestClean)\n",
    "#poly\n",
    "degree = 8\n",
    "lambda_ = 0.001\n",
    "x1TrainPoly = build_poly(x1TrainClean[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x1TrainClean.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x1TrainClean[:,i], degree)\n",
    "    x1TrainPoly = np.concatenate((x1TrainPoly, toAdd), axis=1)\n",
    "w1RidgePoly = ridge_regression(y1Train, x1TrainPoly, lambda_)\n",
    "#get accuracy for this specific category\n",
    "x1TestPoly = build_poly(x1TestClean[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x1TestClean.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x1TestClean[:,i], degree)\n",
    "    x1TestPoly = np.concatenate((x1TestPoly, toAdd), axis=1)\n",
    "acc1 = get_accuracy(x1TestPoly@w1RidgePoly, y1Test)\n",
    "print(\"Accuracy for category 1 with ridge with mean is\" , acc1*100, \"%.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6739ed37-f55f-4198-bdb9-0f508c3352c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for category 2 with ridge with median is 81.44329896907216 %.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#try SOMETHING WITH THE MEDIAN + NORMALIZE\n",
    "#CAT2\n",
    "#separate data\n",
    "ratio = 0.99\n",
    "x2Train, y2Train, x2Test, y2Test = split_data(x2, y2, ratio)\n",
    "#simple normalization\n",
    "x2TrainClean = x2Train\n",
    "x2TestClean = x2Test\n",
    "#put -999.0 values to nan\n",
    "x2TrainClean[x2TrainClean == -999] = np.nan\n",
    "x2TestClean[x2TestClean == -999] = np.nan\n",
    "#this computes the median without the influence of the -999s\n",
    "_, x2TrainMean, _  = clean_data(x2TrainClean)\n",
    "_, x2TestMean, _  = clean_data(x2TestClean)\n",
    "#replace Nan with the mean of the corresponding column\n",
    "for i in range(len(x2TrainMean)):\n",
    "    x2TrainClean[:,i] = np.nan_to_num(x2TrainClean[:,i], nan=x2TrainMean[i])\n",
    "for i in range(len(x2TestMean)):\n",
    "    x2TestClean[:,i] = np.nan_to_num(x2TestClean[:,i], nan=x2TestMean[i])\n",
    "#then, normalize this\n",
    "x2TrainClean, _, _ = clean_data(x2TrainClean)\n",
    "x2TestClean, _, _ = clean_data(x2TestClean)\n",
    "#poly\n",
    "degree = 8\n",
    "lambda_ = 0.001\n",
    "x2TrainPoly = build_poly(x2TrainClean[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x2TrainClean.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x2TrainClean[:,i], degree)\n",
    "    x2TrainPoly = np.concatenate((x2TrainPoly, toAdd), axis=1)\n",
    "w2RidgePoly = ridge_regression(y2Train, x2TrainPoly, lambda_)\n",
    "#get accuracy for this specific category\n",
    "x2TestPoly = build_poly(x2TestClean[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x2TestClean.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x2TestClean[:,i], degree)\n",
    "    x2TestPoly = np.concatenate((x2TestPoly, toAdd), axis=1)\n",
    "acc2 = get_accuracy(x2TestPoly@w2RidgePoly, y2Test)\n",
    "print(\"Accuracy for category 2 with ridge with mean is\" , acc2*100, \"%.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "416d13e7-97f9-4154-9fd8-57c3217e0526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for category 3 with ridge with median is 82.92011019283747 %.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#try SOMETHING WITH THE MEDIAN + NORMALIZE\n",
    "#CAT3\n",
    "#separate data\n",
    "ratio = 0.99\n",
    "x3Train, y3Train, x3Test, y3Test = split_data(x3, y3, ratio)\n",
    "#simple normalization\n",
    "x3TrainClean = x3Train\n",
    "x3TestClean = x3Test\n",
    "#put -999.0 values to nan\n",
    "x3TrainClean[x3TrainClean == -999] = np.nan\n",
    "x3TestClean[x3TestClean == -999] = np.nan\n",
    "#this computes the median without the influence of the -999s\n",
    "_, x3TrainMean, _ = clean_data(x3TrainClean)\n",
    "_, x3TestMean, _ = clean_data(x3TestClean)\n",
    "#replace Nan with the mean of the corresponding column\n",
    "for i in range(len(x3TrainMean)):\n",
    "    x3TrainClean[:,i] = np.nan_to_num(x3TrainClean[:,i], nan=x3TrainMean[i])\n",
    "for i in range(len(x3TestMean)):\n",
    "    x3TestClean[:,i] = np.nan_to_num(x3TestClean[:,i], nan=x3TestMean[i])\n",
    "#then, normalize this\n",
    "x3TrainClean, _, _ = clean_data(x3TrainClean)\n",
    "x3TestClean, _, _ = clean_data(x3TestClean)\n",
    "#poly\n",
    "degree = 8\n",
    "lambda_ = 0.001\n",
    "x3TrainPoly = build_poly(x3TrainClean[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x3TrainClean.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x3TrainClean[:,i], degree)\n",
    "    x3TrainPoly = np.concatenate((x3TrainPoly, toAdd), axis=1)\n",
    "w3RidgePoly = ridge_regression(y3Train, x3TrainPoly, lambda_)\n",
    "#get accuracy for this specific category\n",
    "x3TestPoly = build_poly(x3TestClean[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x3TestClean.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x3TestClean[:,i], degree)\n",
    "    x3TestPoly = np.concatenate((x3TestPoly, toAdd), axis=1)\n",
    "acc3 = get_accuracy(x3TestPoly@w3RidgePoly, y3Test)\n",
    "print(\"Accuracy for category 3 with ridge with mean is\" , acc3*100, \"%.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c3dbd5-ced6-4e8f-a7fd-f45a9b16e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this to make predictions for the website\n",
    "DATA_TEST_PATH = 'test.csv'\n",
    "_, x_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60f5e617-7f22-4cdf-960e-4a01119353de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create prediction based on jet number\n",
    "x1WebTest, x2WebTest, x3WebTest, cat1Id, cat2Id, cat3Id = split_cat_web(x_test) #this also gives position for different categories!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a550212-1ba2-4aed-8a76-64a03d90b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat1 data prep\n",
    "x1TestCleanSub = x1WebTest\n",
    "x1TestCleanSub[x1TestCleanSub == -999] = np.nan\n",
    "_, x1TestMean, _ = clean_data(x1TestCleanSub)\n",
    "for i in range(len(x1TestMean)):\n",
    "    x1TestCleanSub[:,i] = np.nan_to_num(x1TestCleanSub[:,i], nan=x1TestMean[i])\n",
    "x1TestCleanSub, _, _ = clean_data(x1TestCleanSub)\n",
    "#polynomial feature extension\n",
    "degree = 8\n",
    "x1TestPolySub = build_poly(x1TestCleanSub[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x1TestCleanSub.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x1TestCleanSub[:,i], degree)\n",
    "    x1TestPolySub = np.concatenate((x1TestPolySub, toAdd), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c95f6404-8363-4e2c-9f45-42084cf10275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat2 data prep\n",
    "x2TestCleanSub = x2WebTest\n",
    "x2TestCleanSub[x2TestCleanSub == -999] = np.nan\n",
    "_, x2TestMean, _  = clean_data(x2TestCleanSub)\n",
    "for i in range(len(x2TestMean)):\n",
    "    x2TestCleanSub[:,i] = np.nan_to_num(x2TestCleanSub[:,i], nan=x2TestMean[i])\n",
    "x2TestCleanSub, _, _ = clean_data(x2TestCleanSub)\n",
    "#polynomial feature extension\n",
    "degree = 8\n",
    "x2TestPolySub = build_poly(x2TestCleanSub[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x2TestCleanSub.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x2TestCleanSub[:,i], degree)\n",
    "    x2TestPolySub = np.concatenate((x2TestPolySub, toAdd), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0258e943-9d7b-42ea-9663-54b7e3b0ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat3 data prep\n",
    "x3TestCleanSub = x3WebTest\n",
    "x3TestCleanSub[x3TestCleanSub == -999] = np.nan\n",
    "_, x3TestMean, _ = clean_data(x3TestCleanSub)\n",
    "for i in range(len(x3TestMean)):\n",
    "    x3TestCleanSub[:,i] = np.nan_to_num(x3TestCleanSub[:,i], nan=x3TestMean[i])\n",
    "x3TestCleanSub, _, _ = clean_data(x3TestCleanSub)\n",
    "#polynomial feature extension\n",
    "degree = 8\n",
    "x3TestPolySub = build_poly(x3TestCleanSub[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x3TestCleanSub.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x3TestCleanSub[:,i], degree)\n",
    "    x3TestPolySub = np.concatenate((x3TestPolySub, toAdd), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a1d8ac7-cfda-4f45-8192-12efb49fe752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "prediction1 = predict_labels(w1RidgePoly, x1TestPolySub)\n",
    "prediction2 = predict_labels(w2RidgePoly, x2TestPolySub)\n",
    "prediction3 = predict_labels(w3RidgePoly, x3TestPolySub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ce9b377-e4fd-46af-ae77-b0f6d209eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assemble all predictions\n",
    "prediction = np.zeros(len(x_test))\n",
    "prediction[cat1Id] = prediction1\n",
    "prediction[cat2Id] = prediction2\n",
    "prediction[cat3Id] = prediction3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b03ee88-e07d-49b0-babb-6de5a07d33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is it, go to sleep now\n",
    "name = 'prediction17.csv'\n",
    "create_csv_submission(ids_test, prediction, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2286fc07-5b3d-4ff5-a1c7-294932868bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
