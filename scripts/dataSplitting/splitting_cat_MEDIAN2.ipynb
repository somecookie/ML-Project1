{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d50b836a-e39b-430d-9900-2a1bdaf77560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db2c963-ea8b-4481-a007-3c725a27a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'train.csv' # TODO: download train data and supply path here \n",
    "y, x, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "39a03f44-59d2-4926-a0c9-ce2cae4acd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_propre import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "71eaa7be-7858-4c16-a663-6b586dc462a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, separate the data sets in 3 categories\n",
    "x1, x2, x3, y1, y2, y3 = split_cat(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d6d7d8-3dc1-4376-b8eb-47c333eb0517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for category 1 with ridge is 81.78542834267414 %.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#try with a simple median + normalisation + least squares first\n",
    "#CAT1\n",
    "#separate data\n",
    "ratio = 0.90\n",
    "x1Train, y1Train, x1Test, y1Test = split_data(x1, y1, ratio)\n",
    "#simple normalization\n",
    "x1TrainClean, _, _ = clean_data(x1Train)\n",
    "x1TestClean, _, _ = clean_data(x1Test)\n",
    "#poly\n",
    "lambda_ = 0.0001\n",
    "w1 = ridge_regression(y1Train, x1Train, lambda_)\n",
    "#1 = ridge_regression(y1Train, x1Train, lambda_)\n",
    "#get accuracy for this specific category\n",
    "acc1 = get_accuracy(x1Test@w1, y1Test)\n",
    "print(\"Accuracy for category 1 with ridge is\" , acc1*100, \"%.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "89c262c0-80ef-4df5-b9ca-ff7a75bc671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for category 1 with ridge with median is 84.89999999999999 %.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#try SOMETHING WITH THE MEDIAN + NORMALIZE\n",
    "#CAT1\n",
    "#separate data\n",
    "ratio = 0.99\n",
    "x1Train, y1Train, x1Test, y1Test = split_data(x1, y1, ratio)\n",
    "#simple normalization\n",
    "x1TrainClean = x1Train\n",
    "x1TestClean = x1Test\n",
    "#put -999.0 values to nan\n",
    "x1TrainClean[x1TrainClean == -999] = np.nan\n",
    "x1TestClean[x1TestClean == -999] = np.nan\n",
    "#this computes the median without the influence of the -999s\n",
    "_, _, x1TrainMedian = clean_data(x1TrainClean)\n",
    "_, _, x1TestMedian = clean_data(x1TestClean)\n",
    "#replace Nan with the mean of the corresponding column\n",
    "for i in range(len(x1TrainMedian)):\n",
    "    x1TrainClean[:,i] = np.nan_to_num(x1TrainClean[:,i], nan=x1TrainMedian[i])\n",
    "for i in range(len(x1TestMedian)):\n",
    "    x1TestClean[:,i] = np.nan_to_num(x1TestClean[:,i], nan=x1TestMedian[i])\n",
    "#then, normalize this\n",
    "x1TrainClean, _, _ = clean_data(x1TrainClean)\n",
    "x1TestClean, _, _ = clean_data(x1TestClean)\n",
    "#poly\n",
    "degree = 8\n",
    "lambda_ = 0.001\n",
    "x1TrainPoly = build_poly(x1TrainClean[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x1TrainClean.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x1TrainClean[:,i], degree)\n",
    "    x1TrainPoly = np.concatenate((x1TrainPoly, toAdd), axis=1)\n",
    "w1RidgePoly = ridge_regression(y1Train, x1TrainPoly, lambda_)\n",
    "#get accuracy for this specific category\n",
    "x1TestPoly = build_poly(x1TestClean[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x1TestClean.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x1TestClean[:,i], degree)\n",
    "    x1TestPoly = np.concatenate((x1TestPoly, toAdd), axis=1)\n",
    "acc1 = get_accuracy(x1TestPoly@w1RidgePoly, y1Test)\n",
    "print(\"Accuracy for category 1 with ridge with median is\" , acc1*100, \"%.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6739ed37-f55f-4198-bdb9-0f508c3352c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for category 2 with ridge with median is 81.8298969072165 %.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#try SOMETHING WITH THE MEDIAN + NORMALIZE\n",
    "#CAT2\n",
    "#separate data\n",
    "ratio = 0.99\n",
    "x2Train, y2Train, x2Test, y2Test = split_data(x2, y2, ratio)\n",
    "#simple normalization\n",
    "x2TrainClean = x2Train\n",
    "x2TestClean = x2Test\n",
    "#put -999.0 values to nan\n",
    "x2TrainClean[x2TrainClean == -999] = np.nan\n",
    "x2TestClean[x2TestClean == -999] = np.nan\n",
    "#this computes the median without the influence of the -999s\n",
    "_, _, x2TrainMedian = clean_data(x2TrainClean)\n",
    "_, _, x2TestMedian = clean_data(x2TestClean)\n",
    "#replace Nan with the mean of the corresponding column\n",
    "for i in range(len(x2TrainMedian)):\n",
    "    x2TrainClean[:,i] = np.nan_to_num(x2TrainClean[:,i], nan=x2TrainMedian[i])\n",
    "for i in range(len(x2TestMedian)):\n",
    "    x2TestClean[:,i] = np.nan_to_num(x2TestClean[:,i], nan=x2TestMedian[i])\n",
    "#then, normalize this\n",
    "x2TrainClean, _, _ = clean_data(x2TrainClean)\n",
    "x2TestClean, _, _ = clean_data(x2TestClean)\n",
    "#poly\n",
    "degree = 8\n",
    "lambda_ = 0.001\n",
    "x2TrainPoly = build_poly(x2TrainClean[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x2TrainClean.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x2TrainClean[:,i], degree)\n",
    "    x2TrainPoly = np.concatenate((x2TrainPoly, toAdd), axis=1)\n",
    "w2RidgePoly = ridge_regression(y2Train, x2TrainPoly, lambda_)\n",
    "#get accuracy for this specific category\n",
    "x2TestPoly = build_poly(x2TestClean[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x2TestClean.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x2TestClean[:,i], degree)\n",
    "    x2TestPoly = np.concatenate((x2TestPoly, toAdd), axis=1)\n",
    "acc2 = get_accuracy(x2TestPoly@w2RidgePoly, y2Test)\n",
    "print(\"Accuracy for category 2 with ridge with median is\" , acc2*100, \"%.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "416d13e7-97f9-4154-9fd8-57c3217e0526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for category 3 with ridge with median is 82.92011019283747 %.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#try SOMETHING WITH THE MEDIAN + NORMALIZE\n",
    "#CAT3\n",
    "#separate data\n",
    "ratio = 0.99\n",
    "x3Train, y3Train, x3Test, y3Test = split_data(x3, y3, ratio)\n",
    "#simple normalization\n",
    "x3TrainClean = x3Train\n",
    "x3TestClean = x3Test\n",
    "#put -999.0 values to nan\n",
    "x3TrainClean[x3TrainClean == -999] = np.nan\n",
    "x3TestClean[x3TestClean == -999] = np.nan\n",
    "#this computes the median without the influence of the -999s\n",
    "_, _, x3TrainMedian = clean_data(x3TrainClean)\n",
    "_, _, x3TestMedian = clean_data(x3TestClean)\n",
    "#replace Nan with the mean of the corresponding column\n",
    "for i in range(len(x3TrainMedian)):\n",
    "    x3TrainClean[:,i] = np.nan_to_num(x3TrainClean[:,i], nan=x3TrainMedian[i])\n",
    "for i in range(len(x3TestMedian)):\n",
    "    x3TestClean[:,i] = np.nan_to_num(x3TestClean[:,i], nan=x3TestMedian[i])\n",
    "#then, normalize this\n",
    "x3TrainClean, _, _ = clean_data(x3TrainClean)\n",
    "x3TestClean, _, _ = clean_data(x3TestClean)\n",
    "#poly\n",
    "degree = 8\n",
    "lambda_ = 0.001\n",
    "x3TrainPoly = build_poly(x3TrainClean[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x3TrainClean.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x3TrainClean[:,i], degree)\n",
    "    x3TrainPoly = np.concatenate((x3TrainPoly, toAdd), axis=1)\n",
    "w3RidgePoly = ridge_regression(y3Train, x3TrainPoly, lambda_)\n",
    "#get accuracy for this specific category\n",
    "x3TestPoly = build_poly(x3TestClean[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x3TestClean.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x3TestClean[:,i], degree)\n",
    "    x3TestPoly = np.concatenate((x3TestPoly, toAdd), axis=1)\n",
    "acc3 = get_accuracy(x3TestPoly@w3RidgePoly, y3Test)\n",
    "print(\"Accuracy for category 3 with ridge with median is\" , acc3*100, \"%.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "62c3dbd5-ced6-4e8f-a7fd-f45a9b16e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this to make predictions for the website\n",
    "DATA_TEST_PATH = 'test.csv'\n",
    "_, x_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "60f5e617-7f22-4cdf-960e-4a01119353de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create prediction based on jet number\n",
    "x1WebTest, x2WebTest, x3WebTest, cat1Id, cat2Id, cat3Id = split_cat_web(x_test) #this also gives position for different categories!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7a550212-1ba2-4aed-8a76-64a03d90b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat1 data prep\n",
    "x1TestCleanSub = x1WebTest\n",
    "x1TestCleanSub[x1TestCleanSub == -999] = np.nan\n",
    "_, _, x1TestMedian = clean_data(x1TestCleanSub)\n",
    "for i in range(len(x1TestMedian)):\n",
    "    x1TestCleanSub[:,i] = np.nan_to_num(x1TestCleanSub[:,i], nan=x1TestMedian[i])\n",
    "x1TestCleanSub, _, _ = clean_data(x1TestCleanSub)\n",
    "#polynomial feature extension\n",
    "degree = 8\n",
    "x1TestPolySub = build_poly(x1TestCleanSub[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x1TestCleanSub.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x1TestCleanSub[:,i], degree)\n",
    "    x1TestPolySub = np.concatenate((x1TestPolySub, toAdd), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c95f6404-8363-4e2c-9f45-42084cf10275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat2 data prep\n",
    "x2TestCleanSub = x2WebTest\n",
    "x2TestCleanSub[x2TestCleanSub == -999] = np.nan\n",
    "_, _, x2TestMedian = clean_data(x2TestCleanSub)\n",
    "for i in range(len(x2TestMedian)):\n",
    "    x2TestCleanSub[:,i] = np.nan_to_num(x2TestCleanSub[:,i], nan=x2TestMedian[i])\n",
    "x2TestCleanSub, _, _ = clean_data(x2TestCleanSub)\n",
    "#polynomial feature extension\n",
    "degree = 8\n",
    "x2TestPolySub = build_poly(x2TestCleanSub[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x2TestCleanSub.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x2TestCleanSub[:,i], degree)\n",
    "    x2TestPolySub = np.concatenate((x2TestPolySub, toAdd), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0258e943-9d7b-42ea-9663-54b7e3b0ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat3 data prep\n",
    "x3TestCleanSub = x3WebTest\n",
    "x3TestCleanSub[x3TestCleanSub == -999] = np.nan\n",
    "_, _, x3TestMedian = clean_data(x3TestCleanSub)\n",
    "for i in range(len(x3TestMedian)):\n",
    "    x3TestCleanSub[:,i] = np.nan_to_num(x3TestCleanSub[:,i], nan=x3TestMedian[i])\n",
    "x3TestCleanSub, _, _ = clean_data(x3TestCleanSub)\n",
    "#polynomial feature extension\n",
    "degree = 8\n",
    "x3TestPolySub = build_poly(x3TestCleanSub[:,0], degree) #begin by building the polynomal feature\n",
    "for i in range(1,len(x3TestCleanSub.T)-1): #do this for every feature\n",
    "    toAdd = build_poly(x3TestCleanSub[:,i], degree)\n",
    "    x3TestPolySub = np.concatenate((x3TestPolySub, toAdd), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3a1d8ac7-cfda-4f45-8192-12efb49fe752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "prediction1 = predict_labels(w1RidgePoly, x1TestPolySub)\n",
    "prediction2 = predict_labels(w2RidgePoly, x2TestPolySub)\n",
    "prediction3 = predict_labels(w3RidgePoly, x3TestPolySub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6ce9b377-e4fd-46af-ae77-b0f6d209eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assemble all predictions\n",
    "prediction = np.zeros(len(x_test))\n",
    "prediction[cat1Id] = prediction1\n",
    "prediction[cat2Id] = prediction2\n",
    "prediction[cat3Id] = prediction3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1b03ee88-e07d-49b0-babb-6de5a07d33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is it, go to sleep now\n",
    "name = 'prediction16.csv'\n",
    "create_csv_submission(ids_test, prediction, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2286fc07-5b3d-4ff5-a1c7-294932868bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
